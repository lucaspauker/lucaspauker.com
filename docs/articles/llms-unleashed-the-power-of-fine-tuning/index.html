<!DOCTYPE html>
<html lang="en" dir="auto">

<head><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="robots" content="index, follow">
<title>LLMs Unleashed: The Power of Fine-Tuning | Lucas Pauker</title>
<meta name="keywords" content="AI, CS">
<meta name="description" content="Disclaimer: This article mentions https://terra-cotta.ai/, an LLM experimentation platform I am building
Introduction ChatGPT, Bard, and other large language models (LLMs) are very useful for a wide variety of tasks from writing code to answering complex questions to aiding with education. However, these models are ultimately limited by the data that they are trained on. Also, these models are trained to be able to answer a wide variety of questions which may not be sufficient for domain-specific questions.">
<meta name="author" content="Lucas Pauker">
<link rel="canonical" href="https://lucaspauker.com/articles/llms-unleashed-the-power-of-fine-tuning/">
<link crossorigin="anonymous" href="/assets/css/stylesheet.583299ed92beb6d4b9dc3b06ae47dbb8539f349d135b5c88394b12d0fc81f275.css" integrity="sha256-WDKZ7ZK&#43;ttS53DsGrkfbuFOfNJ0TW1yIOUsS0PyB8nU=" rel="preload stylesheet" as="style">
<link rel="icon" href="https://lucaspauker.com/images/logo/favicon.ico">
<link rel="icon" type="image/png" sizes="16x16" href="https://lucaspauker.com/images/logo/favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="https://lucaspauker.com/images/logo/favicon-32x32.png">
<link rel="apple-touch-icon" href="https://lucaspauker.com/images/logo/apple-touch-icon.png">
<link rel="mask-icon" href="https://lucaspauker.com/safari-pinned-tab.svg">
<meta name="theme-color" content="#2e2e33">
<meta name="msapplication-TileColor" content="#2e2e33">
<link rel="alternate" hreflang="en" href="https://lucaspauker.com/articles/llms-unleashed-the-power-of-fine-tuning/">
<noscript>
    <style>
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
</noscript><script async src="https://www.googletagmanager.com/gtag/js?id=G-49CCEN1B6K"></script>
<script>
	window.dataLayer = window.dataLayer || [];
	function gtag(){dataLayer.push(arguments);}
	gtag('js', new Date());
	gtag('config', 'G-49CCEN1B6K', {
		'anonymize_ip':  false ,
		'cookie_flags': 'SameSite=None; Secure'
	});
</script><meta property="og:title" content="LLMs Unleashed: The Power of Fine-Tuning" />
<meta property="og:description" content="Disclaimer: This article mentions https://terra-cotta.ai/, an LLM experimentation platform I am building
Introduction ChatGPT, Bard, and other large language models (LLMs) are very useful for a wide variety of tasks from writing code to answering complex questions to aiding with education. However, these models are ultimately limited by the data that they are trained on. Also, these models are trained to be able to answer a wide variety of questions which may not be sufficient for domain-specific questions." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://lucaspauker.com/articles/llms-unleashed-the-power-of-fine-tuning/" /><meta property="og:image" content="https://lucaspauker.com/images/papermod-cover.png"/><meta property="article:section" content="articles" />
<meta property="article:published_time" content="2023-07-23T00:00:00+00:00" />
<meta property="article:modified_time" content="2023-07-23T00:00:00+00:00" />

<meta name="twitter:card" content="summary_large_image"/>
<meta name="twitter:image" content="https://lucaspauker.com/images/papermod-cover.png"/>

<meta name="twitter:title" content="LLMs Unleashed: The Power of Fine-Tuning"/>
<meta name="twitter:description" content="Disclaimer: This article mentions https://terra-cotta.ai/, an LLM experimentation platform I am building
Introduction ChatGPT, Bard, and other large language models (LLMs) are very useful for a wide variety of tasks from writing code to answering complex questions to aiding with education. However, these models are ultimately limited by the data that they are trained on. Also, these models are trained to be able to answer a wide variety of questions which may not be sufficient for domain-specific questions."/>


<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BreadcrumbList",
  "itemListElement": [
    {
      "@type": "ListItem",
      "position":  1 ,
      "name": "Articles",
      "item": "https://lucaspauker.com/articles/"
    }, 
    {
      "@type": "ListItem",
      "position":  2 ,
      "name": "LLMs Unleashed: The Power of Fine-Tuning",
      "item": "https://lucaspauker.com/articles/llms-unleashed-the-power-of-fine-tuning/"
    }
  ]
}
</script>
<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "LLMs Unleashed: The Power of Fine-Tuning",
  "name": "LLMs Unleashed: The Power of Fine-Tuning",
  "description": "Disclaimer: This article mentions https://terra-cotta.ai/, an LLM experimentation platform I am building\nIntroduction ChatGPT, Bard, and other large language models (LLMs) are very useful for a wide variety of tasks from writing code to answering complex questions to aiding with education. However, these models are ultimately limited by the data that they are trained on. Also, these models are trained to be able to answer a wide variety of questions which may not be sufficient for domain-specific questions.",
  "keywords": [
    "AI", "CS"
  ],
  "articleBody": "Disclaimer: This article mentions https://terra-cotta.ai/, an LLM experimentation platform I am building\nIntroduction ChatGPT, Bard, and other large language models (LLMs) are very useful for a wide variety of tasks from writing code to answering complex questions to aiding with education. However, these models are ultimately limited by the data that they are trained on. Also, these models are trained to be able to answer a wide variety of questions which may not be sufficient for domain-specific questions. Fine-tuning is essential in order to make these models accurately answer domain-specific questions and be useful for difficult tasks. Furthermore, fine-tuning may be cheaper for inference.\nFine-tuning is the process of training an LLM on your own custom data. The fine-tuning process begins with a generic LLM that is pretrained on a large amount of text data. Fine tuning updates the generic model’s parameters or weights by using a smaller dataset for a target task.\nOne example of a task where fine-tuning is necessary is getting a medical diagnosis from raw medical records, such as electronic health records or medical imaging reports. ChatGPT is unlikely to perform this task well since it lacks specialized knowledge in medical domains and direct experience with real medical cases. ChatGPT will usually generate a confident response to any query, but the response cannot always be trusted due to hallucinations, where the model returns incorrect information [1]. Hallucinations are common for difficult tasks. Fine-tuning a language model specifically on validated, trusted medical data is essential to ensure accurate and reliable results. A fine-tuned model would learn the domain-specific knowledge and likely be able to return accurate diagnoses for this task.\nThe idea of fine-tuning has a strong research pedigree. The approach can be traced back to 2018, when two influential papers were published. The first paper, “Improving Language Understanding by Generative Pre-Training” by Radford et al. [2] introduces the GPT model that is now used in ChatGPT. GPT used self-supervised learning to train an LLM on a large amount of unlabeled data. In the paper, the authors show that their GPT model could achieve state-of-the-art results on multiple tasks by fine-tuning their model on specific datasets. Similarly, “BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding” by Devlin et al. [3] introduced BERT, a novel transformer model and showed the ability for it to be fine-tuned and achieve state-of-the-art performance on multiple tasks after fine-tuning. The image below shows how BERT can be fine-tuned on specific tasks such as SQuAD.\nImage from BERT paper [3]\nFine-tuning vs. prompting Fine-tuning and prompting are two ways to solve tasks with LLMs. Fine-tuning adapts an LLM with a dataset by updating the model’s parameters. On the other hand, prompting refers to a user inputting specific instructions or text as prompts into a generalized (not fine-tuned) LLM to guide the model’s response. One-shot and few-shot prompting are examples of prompting techniques. In the image below, we can see how zero-shot, one-shot, and few-shot prompting compare to fine-tuning. Note that the prompts for the prompting examples are longer than the fine-tuning prompt.\nImage from GPT-3 paper [4]\nBoth fine-tuning and prompting are valuable techniques for using LLMs. Depending on the specific use case, one method or the other may be better. In general, fine-tuning is better for complex tasks where the user has a labeled dataset and may be cheaper in the long run due to cheaper inference costs, depending on the LLM provider.\nFor simple tasks, prompting has advantages over fine-tuning. First, prompting is faster to iterate on since you do not need to train a new model every time you update the prompt or change your dataset. Second, fine-tuning requires a labeled dataset, while prompting does not. Therefore, if you do not have training data or only have a few examples, prompting could be better. In general, it makes sense to start with prompting and seeing if it can solve your task before trying fine-tuning.\nFine tuning is better for complex tasks where the model’s generated output must be accurate and trusted. In the GPT-3 paper, “Language Models are Few-Shot Learners” by Brown et al. [4], the authors compare few shot prompting on GPT-3 to fine-tuned models for many different tasks. Often, GPT-3 cannot outperform the fine-tuned models, especially on complex tasks. Each task is measured with performance measures such as accuracy or BLEU score (an NLP metric). One task where few-shot GPT-3 greatly underperforms fine-tuned models is natural language inference (NLI) tasks. In this task, there are two sentences and the model has to predict if the second sentence logically follows from the first. The non-fine-tuned model likely does not perform well since this task is difficult and requires an understanding of logic. Intuitively, fine-tuning outperforms prompting for complex tasks since one can train on an unlimited number of domain specific data points.\nImage from GPT-3 paper [4]\nFurthermore, inference is significantly cheaper with fine-tuned models when compared to prompted models due to the reduction in the amount of instruction required during prediction. Since fine-tuning allows developers to incorporate task-specific knowledge directly into the model’s parameters,, fine-tuned models can generate accurate responses with minimal need for explicit instructions or prompts during inference. On the other hand, prompted models heavily rely on explicit prompts or instructions for each prediction, which can be computationally expensive and resource-intensive, especially for large-scale applications.\nSteps to fine-tune a model Fine-tuning an LLM involves many steps including curating your data and picking the best architecture. Here are the general steps to fine-tune a LLM model:\nDefine task and dataset Select LLM architecture Update model weights Select hyperparameters Evaluate model Deploy model OpenAI lets you fine-tune their GPT-3 models on your custom data (in the future, they will add support for GPT-3.5 and GPT-4). We built a free platform to easily guide you through the steps above to fine-tune OpenAI LLMs here: https://terra-cotta.ai/. With the platform, you can also compare fine-tuned models to prompted models.\nIn conclusion, fine-tuning is a powerful technique that allows developers to leverage the knowledge and capabilities of pretrained language models while adapting them to specific real-world tasks, leading to improved accuracy and cost performance for a wide range of natural language processing applications.\nCitations https://arxiv.org/pdf/2305.14552v1.pdf https://s3-us-west-2.amazonaws.com/openai-assets/research-covers/language-unsupervised/language_understanding_paper.pdf https://arxiv.org/pdf/1810.04805.pdf https://arxiv.org/pdf/2005.14165.pdf ",
  "wordCount" : "1037",
  "inLanguage": "en",
  "datePublished": "2023-07-23T00:00:00Z",
  "dateModified": "2023-07-23T00:00:00Z",
  "author":{
    "@type": "Person",
    "name": "Lucas Pauker"
  },
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "https://lucaspauker.com/articles/llms-unleashed-the-power-of-fine-tuning/"
  },
  "publisher": {
    "@type": "Organization",
    "name": "Lucas Pauker",
    "logo": {
      "@type": "ImageObject",
      "url": "https://lucaspauker.com/images/logo/favicon.ico"
    }
  }
}
</script><script type="text/javascript" id="MathJax-script" async
  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js">
</script>


</head>

<body class="" id="top">
<script>
    if (localStorage.getItem("pref-theme") === "dark") {
        document.body.classList.add('dark');
    }

</script>

<header class="header">
    <nav class="nav">
        <div class="logo">
            <a href="https://lucaspauker.com/" accesskey="h" title="Lucas Pauker (Alt + H)"></a>
            <div class="logo-switches">
                <button id="theme-toggle" accesskey="t" title="(Alt + T)">
                    <svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path>
                    </svg>
                    <svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <circle cx="12" cy="12" r="5"></circle>
                        <line x1="12" y1="1" x2="12" y2="3"></line>
                        <line x1="12" y1="21" x2="12" y2="23"></line>
                        <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
                        <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
                        <line x1="1" y1="12" x2="3" y2="12"></line>
                        <line x1="21" y1="12" x2="23" y2="12"></line>
                        <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
                        <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
                    </svg>
                </button>
                </ul>
            </div>
        </div>
        <ul id="menu">
            <li>
                <a href="https://lucaspauker.com/" title="Blog">
                    <span>Blog</span>
                </a>
            </li>
            <li>
                <a href="https://lucaspauker.com/about" title="About me">
                    <span>About me</span>
                </a>
            </li>
            <li>
                <a href="https://lucaspauker.com/projects" title="Projects">
                    <span>Projects</span>
                </a>
            </li>
        </ul>
    </nav>
</header>
<main class="main">

<article class="post-single">
  <header class="post-header">
    <div class="breadcrumbs"><a href="https://lucaspauker.com/">Home</a>&nbsp;»&nbsp;<a href="https://lucaspauker.com/articles/">Articles</a></div>
    <h1 class="post-title entry-hint-parent">
      LLMs Unleashed: The Power of Fine-Tuning
    </h1>
    <div class="post-meta"><span title='2023-07-23 00:00:00 +0000 UTC'>July 23, 2023</span>&nbsp;·&nbsp;5 min&nbsp;·&nbsp;Lucas Pauker

</div>
  </header> <div class="toc">
    <details >
        <summary accesskey="c" title="(Alt + C)">
            <span class="details">Table of Contents</span>
        </summary>

        <div class="inner"><ul>
                <li>
                    <a href="#introduction" aria-label="Introduction">Introduction</a></li>
                <li>
                    <a href="#fine-tuning-vs-prompting" aria-label="Fine-tuning vs. prompting">Fine-tuning vs. prompting</a></li>
                <li>
                    <a href="#steps-to-fine-tune-a-model" aria-label="Steps to fine-tune a model">Steps to fine-tune a model</a></li>
                <li>
                    <a href="#citations" aria-label="Citations">Citations</a>
                </li>
            </ul>
        </div>
    </details>
</div>

  <div class="post-content"><p><em>Disclaimer: This article mentions <a href="https://terra-cotta.ai/">https://terra-cotta.ai/</a>, an LLM experimentation platform I am building</em></p>
<h2 id="introduction">Introduction<a hidden class="anchor" aria-hidden="true" href="#introduction">#</a></h2>
<p>ChatGPT, Bard, and other large language models (LLMs) are very useful for a wide variety of tasks from writing code to answering complex questions to aiding with education. However, these models are ultimately limited by the data that they are trained on. Also, these models are trained to be able to answer a wide variety of questions which may not be sufficient for domain-specific questions. Fine-tuning is essential in order to make these models accurately answer domain-specific questions and be useful for difficult tasks. Furthermore, fine-tuning may be cheaper for inference.</p>
<p>Fine-tuning is the process of training an LLM  on your own custom data. The fine-tuning process begins with a generic LLM that is pretrained on a large amount of text data. Fine tuning updates the generic model’s parameters or weights by using a smaller dataset for a target task.</p>
<p>One example of a task where fine-tuning is necessary is getting a medical diagnosis from raw medical records, such as electronic health records or medical imaging reports. ChatGPT is unlikely to perform this task well since it lacks specialized knowledge in medical domains and direct experience with real medical cases. ChatGPT will usually generate a confident response to any query, but the response cannot always be trusted due to hallucinations, where the model returns incorrect information <a href="https://arxiv.org/pdf/2305.14552v1.pdf">[1]</a>. Hallucinations are common for difficult tasks. Fine-tuning a language model specifically on validated, trusted medical data is essential to ensure accurate and reliable results. A fine-tuned model would learn the domain-specific knowledge and likely be able to return accurate diagnoses for this task.</p>
<p>The idea of fine-tuning has a strong research pedigree. The approach can be traced back to 2018, when two influential papers were published. The first paper, “Improving Language Understanding by Generative Pre-Training” by Radford et al. <a href="https://s3-us-west-2.amazonaws.com/openai-assets/research-covers/language-unsupervised/language_understanding_paper.pdf">[2]</a> introduces the GPT model that is now used in ChatGPT. GPT used self-supervised learning to train an LLM on a large amount of unlabeled data. In the paper, the authors show that their GPT model could achieve state-of-the-art results on multiple tasks by fine-tuning their model on specific datasets. Similarly, “BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding” by Devlin et al. <a href="https://arxiv.org/pdf/1810.04805.pdf">[3]</a> introduced BERT, a novel transformer model and showed the ability for it to be fine-tuned and achieve state-of-the-art performance on multiple tasks after fine-tuning. The image below shows how BERT can be fine-tuned on specific tasks such as SQuAD.</p>
<p><img loading="lazy" src="/images/finetuning/bert_finetuning.png" alt="Image from BERT paper [3]"  />

<em>Image from BERT paper <a href="https://arxiv.org/pdf/1810.04805.pdf">[3]</a></em></p>
<h2 id="fine-tuning-vs-prompting">Fine-tuning vs. prompting<a hidden class="anchor" aria-hidden="true" href="#fine-tuning-vs-prompting">#</a></h2>
<p>Fine-tuning and  prompting are  two ways to solve tasks with LLMs. Fine-tuning adapts  an LLM with a dataset by updating the model’s parameters. On the other hand, prompting refers to a user inputting  specific instructions or text as prompts into a generalized (not fine-tuned) LLM to guide the model&rsquo;s response. One-shot and few-shot prompting are examples of prompting techniques. In the image below, we can see how zero-shot, one-shot, and few-shot prompting compare to fine-tuning. Note that the prompts for the prompting examples are longer than the fine-tuning prompt.</p>
<p><img loading="lazy" src="/images/finetuning/prompting_vs_finetuning.png" alt="Image from GPT-3 paper [4]"  />

<em>Image from GPT-3 paper <a href="https://arxiv.org/pdf/2005.14165.pdf">[4]</a></em></p>
<p>Both fine-tuning and prompting are valuable techniques for using LLMs. Depending on the specific use case, one method or the other may be better. In general, fine-tuning is better for complex tasks where the user has a labeled dataset and may be cheaper in the long run due to cheaper inference costs, depending on the LLM provider.</p>
<p>For simple tasks, prompting has advantages over fine-tuning. First, prompting is faster to iterate on since you do not need to train a new model every time you update the prompt or change your dataset. Second, fine-tuning requires a labeled dataset, while prompting does not. Therefore, if you do not have training data or only have a few examples, prompting could be better. In general, it makes sense to start with prompting and seeing if it can solve your task before trying fine-tuning.</p>
<p>Fine tuning is better for complex tasks where the model’s generated output must be accurate and trusted. In the GPT-3 paper, “Language Models are Few-Shot Learners” by Brown et al. <a href="https://arxiv.org/pdf/2005.14165.pdf">[4]</a>, the authors compare few shot prompting on GPT-3 to fine-tuned models for many different tasks. Often, GPT-3 cannot outperform the fine-tuned models, especially on complex tasks. Each task is measured with performance measures such as accuracy or BLEU score (an NLP metric). One task where few-shot GPT-3 greatly underperforms fine-tuned models is natural language inference (NLI) tasks. In this task, there are two sentences and the model has to predict if the second sentence logically follows from the first. The non-fine-tuned model likely does not perform well since this task is difficult and requires an understanding of logic. Intuitively, fine-tuning outperforms prompting for complex tasks since one can train on an unlimited number of domain specific data points.</p>
<p><img loading="lazy" src="/images/finetuning/anli_graph.png" alt="Image from GPT-3 paper [4]"  />

<em>Image from GPT-3 paper <a href="https://arxiv.org/pdf/2005.14165.pdf">[4]</a></em></p>
<p>Furthermore, inference is significantly cheaper with fine-tuned models when compared to prompted models due to the reduction in the amount of instruction required during prediction. Since fine-tuning allows developers to incorporate task-specific knowledge directly into the model&rsquo;s parameters,, fine-tuned models can generate accurate responses with minimal need for explicit instructions or prompts during inference. On the other hand, prompted models heavily rely on explicit prompts or instructions for each prediction, which can be computationally expensive and resource-intensive, especially for large-scale applications.</p>
<h2 id="steps-to-fine-tune-a-model">Steps to fine-tune a model<a hidden class="anchor" aria-hidden="true" href="#steps-to-fine-tune-a-model">#</a></h2>
<p>Fine-tuning an LLM involves many steps including curating your data and picking the best architecture. Here are the general steps to fine-tune a LLM model:</p>
<ol>
<li>Define task and dataset</li>
<li>Select LLM architecture</li>
<li>Update model weights</li>
<li>Select hyperparameters</li>
<li>Evaluate model</li>
<li>Deploy model</li>
</ol>
<p>OpenAI lets you fine-tune their GPT-3 models on your custom data (in the future, they will add support for GPT-3.5 and GPT-4). We built a free platform to easily guide you through the steps above to fine-tune OpenAI LLMs here: <a href="https://terra-cotta.ai/">https://terra-cotta.ai/</a>. With the platform, you can also compare fine-tuned models to prompted models.</p>
<p>In conclusion, fine-tuning is a powerful technique that allows developers to leverage the knowledge and capabilities of pretrained language models while adapting them to specific real-world tasks, leading to improved accuracy and cost performance for a wide range of natural language processing applications.</p>
<h2 id="citations">Citations<a hidden class="anchor" aria-hidden="true" href="#citations">#</a></h2>
<ol>
<li><a href="https://arxiv.org/pdf/2305.14552v1.pdf">https://arxiv.org/pdf/2305.14552v1.pdf</a></li>
<li><a href="https://s3-us-west-2.amazonaws.com/openai-assets/research-covers/language-unsupervised/language_understanding_paper.pdf">https://s3-us-west-2.amazonaws.com/openai-assets/research-covers/language-unsupervised/language_understanding_paper.pdf</a></li>
<li><a href="https://arxiv.org/pdf/1810.04805.pdf">https://arxiv.org/pdf/1810.04805.pdf</a></li>
<li><a href="https://arxiv.org/pdf/2005.14165.pdf">https://arxiv.org/pdf/2005.14165.pdf</a></li>
</ol>


  </div>

  <footer class="post-footer">
    <ul class="post-tags">
      <li><a href="https://lucaspauker.com/tags/ai/">AI</a></li>
      <li><a href="https://lucaspauker.com/tags/cs/">CS</a></li>
    </ul>
    <script src="https://utteranc.es/client.js"
        repo="lucaspauker/lucaspauker.com"
        issue-term="url"
        theme="github-light"
        crossorigin="anonymous"
        async>
    </script>
<nav class="paginav">
  <a class="prev" href="https://lucaspauker.com/articles/openai-model-timing/">
    <span class="title">« Prev</span>
    <br>
    <span>OpenAI Model Timing</span>
  </a>
  <a class="next" href="https://lucaspauker.com/articles/50-practical-applications-of-artificial-intelligence-and-language-models/">
    <span class="title">Next »</span>
    <br>
    <span>50 AI Applications</span>
  </a>
</nav>


<ul class="share-buttons">
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share LLMs Unleashed: The Power of Fine-Tuning on x"
            href="https://x.com/intent/tweet/?text=LLMs%20Unleashed%3a%20The%20Power%20of%20Fine-Tuning&amp;url=https%3a%2f%2flucaspauker.com%2farticles%2fllms-unleashed-the-power-of-fine-tuning%2f&amp;hashtags=AI%2cCS">
            <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
                <path
                    d="M512 62.554 L 512 449.446 C 512 483.97 483.97 512 449.446 512 L 62.554 512 C 28.03 512 0 483.97 0 449.446 L 0 62.554 C 0 28.03 28.029 0 62.554 0 L 449.446 0 C 483.971 0 512 28.03 512 62.554 Z M 269.951 190.75 L 182.567 75.216 L 56 75.216 L 207.216 272.95 L 63.9 436.783 L 125.266 436.783 L 235.9 310.383 L 332.567 436.783 L 456 436.783 L 298.367 228.367 L 432.367 75.216 L 371.033 75.216 Z M 127.633 110 L 164.101 110 L 383.481 400.065 L 349.5 400.065 Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share LLMs Unleashed: The Power of Fine-Tuning on linkedin"
            href="https://www.linkedin.com/shareArticle?mini=true&amp;url=https%3a%2f%2flucaspauker.com%2farticles%2fllms-unleashed-the-power-of-fine-tuning%2f&amp;title=LLMs%20Unleashed%3a%20The%20Power%20of%20Fine-Tuning&amp;summary=LLMs%20Unleashed%3a%20The%20Power%20of%20Fine-Tuning&amp;source=https%3a%2f%2flucaspauker.com%2farticles%2fllms-unleashed-the-power-of-fine-tuning%2f">
            <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
                <path
                    d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-386.892,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Zm-288.985,423.278l0,-225.717l-75.04,0l0,225.717l75.04,0Zm270.539,0l0,-129.439c0,-69.333 -37.018,-101.586 -86.381,-101.586c-39.804,0 -57.634,21.891 -67.617,37.266l0,-31.958l-75.021,0c0.995,21.181 0,225.717 0,225.717l75.02,0l0,-126.056c0,-6.748 0.486,-13.492 2.474,-18.315c5.414,-13.475 17.767,-27.434 38.494,-27.434c27.135,0 38.007,20.707 38.007,51.037l0,120.768l75.024,0Zm-307.552,-334.556c-25.674,0 -42.448,16.879 -42.448,39.002c0,21.658 16.264,39.002 41.455,39.002l0.484,0c26.165,0 42.452,-17.344 42.452,-39.002c-0.485,-22.092 -16.241,-38.954 -41.943,-39.002Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share LLMs Unleashed: The Power of Fine-Tuning on reddit"
            href="https://reddit.com/submit?url=https%3a%2f%2flucaspauker.com%2farticles%2fllms-unleashed-the-power-of-fine-tuning%2f&title=LLMs%20Unleashed%3a%20The%20Power%20of%20Fine-Tuning">
            <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
                <path
                    d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-386.892,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Zm-3.446,265.638c0,-22.964 -18.616,-41.58 -41.58,-41.58c-11.211,0 -21.361,4.457 -28.841,11.666c-28.424,-20.508 -67.586,-33.757 -111.204,-35.278l18.941,-89.121l61.884,13.157c0.756,15.734 13.642,28.29 29.56,28.29c16.407,0 29.706,-13.299 29.706,-29.701c0,-16.403 -13.299,-29.702 -29.706,-29.702c-11.666,0 -21.657,6.792 -26.515,16.578l-69.105,-14.69c-1.922,-0.418 -3.939,-0.042 -5.585,1.036c-1.658,1.073 -2.811,2.761 -3.224,4.686l-21.152,99.438c-44.258,1.228 -84.046,14.494 -112.837,35.232c-7.468,-7.164 -17.589,-11.591 -28.757,-11.591c-22.965,0 -41.585,18.616 -41.585,41.58c0,16.896 10.095,31.41 24.568,37.918c-0.639,4.135 -0.99,8.328 -0.99,12.576c0,63.977 74.469,115.836 166.33,115.836c91.861,0 166.334,-51.859 166.334,-115.836c0,-4.218 -0.347,-8.387 -0.977,-12.493c14.564,-6.47 24.735,-21.034 24.735,-38.001Zm-119.474,108.193c-20.27,20.241 -59.115,21.816 -70.534,21.816c-11.428,0 -50.277,-1.575 -70.522,-21.82c-3.007,-3.008 -3.007,-7.882 0,-10.889c3.003,-2.999 7.882,-3.003 10.885,0c12.777,12.781 40.11,17.317 59.637,17.317c19.522,0 46.86,-4.536 59.657,-17.321c3.016,-2.999 7.886,-2.995 10.885,0.008c3.008,3.011 3.003,7.882 -0.008,10.889Zm-5.23,-48.781c-16.373,0 -29.701,-13.324 -29.701,-29.698c0,-16.381 13.328,-29.714 29.701,-29.714c16.378,0 29.706,13.333 29.706,29.714c0,16.374 -13.328,29.698 -29.706,29.698Zm-160.386,-29.702c0,-16.381 13.328,-29.71 29.714,-29.71c16.369,0 29.689,13.329 29.689,29.71c0,16.373 -13.32,29.693 -29.689,29.693c-16.386,0 -29.714,-13.32 -29.714,-29.693Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share LLMs Unleashed: The Power of Fine-Tuning on facebook"
            href="https://facebook.com/sharer/sharer.php?u=https%3a%2f%2flucaspauker.com%2farticles%2fllms-unleashed-the-power-of-fine-tuning%2f">
            <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
                <path
                    d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-106.468,0l0,-192.915l66.6,0l12.672,-82.621l-79.272,0l0,-53.617c0,-22.603 11.073,-44.636 46.58,-44.636l36.042,0l0,-70.34c0,0 -32.71,-5.582 -63.982,-5.582c-65.288,0 -107.96,39.569 -107.96,111.204l0,62.971l-72.573,0l0,82.621l72.573,0l0,192.915l-191.104,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share LLMs Unleashed: The Power of Fine-Tuning on whatsapp"
            href="https://api.whatsapp.com/send?text=LLMs%20Unleashed%3a%20The%20Power%20of%20Fine-Tuning%20-%20https%3a%2f%2flucaspauker.com%2farticles%2fllms-unleashed-the-power-of-fine-tuning%2f">
            <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
                <path
                    d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-386.892,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Zm-58.673,127.703c-33.842,-33.881 -78.847,-52.548 -126.798,-52.568c-98.799,0 -179.21,80.405 -179.249,179.234c-0.013,31.593 8.241,62.428 23.927,89.612l-25.429,92.884l95.021,-24.925c26.181,14.28 55.659,21.807 85.658,21.816l0.074,0c98.789,0 179.206,-80.413 179.247,-179.243c0.018,-47.895 -18.61,-92.93 -52.451,-126.81Zm-126.797,275.782l-0.06,0c-26.734,-0.01 -52.954,-7.193 -75.828,-20.767l-5.441,-3.229l-56.386,14.792l15.05,-54.977l-3.542,-5.637c-14.913,-23.72 -22.791,-51.136 -22.779,-79.287c0.033,-82.142 66.867,-148.971 149.046,-148.971c39.793,0.014 77.199,15.531 105.329,43.692c28.128,28.16 43.609,65.592 43.594,105.4c-0.034,82.149 -66.866,148.983 -148.983,148.984Zm81.721,-111.581c-4.479,-2.242 -26.499,-13.075 -30.604,-14.571c-4.105,-1.495 -7.091,-2.241 -10.077,2.241c-2.986,4.483 -11.569,14.572 -14.182,17.562c-2.612,2.988 -5.225,3.364 -9.703,1.12c-4.479,-2.241 -18.91,-6.97 -36.017,-22.23c-13.314,-11.876 -22.304,-26.542 -24.916,-31.026c-2.612,-4.484 -0.279,-6.908 1.963,-9.14c2.016,-2.007 4.48,-5.232 6.719,-7.847c2.24,-2.615 2.986,-4.484 4.479,-7.472c1.493,-2.99 0.747,-5.604 -0.374,-7.846c-1.119,-2.241 -10.077,-24.288 -13.809,-33.256c-3.635,-8.733 -7.327,-7.55 -10.077,-7.688c-2.609,-0.13 -5.598,-0.158 -8.583,-0.158c-2.986,0 -7.839,1.121 -11.944,5.604c-4.105,4.484 -15.675,15.32 -15.675,37.364c0,22.046 16.048,43.342 18.287,46.332c2.24,2.99 31.582,48.227 76.511,67.627c10.685,4.615 19.028,7.371 25.533,9.434c10.728,3.41 20.492,2.929 28.209,1.775c8.605,-1.285 26.499,-10.833 30.231,-21.295c3.732,-10.464 3.732,-19.431 2.612,-21.298c-1.119,-1.869 -4.105,-2.99 -8.583,-5.232Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share LLMs Unleashed: The Power of Fine-Tuning on telegram"
            href="https://telegram.me/share/url?text=LLMs%20Unleashed%3a%20The%20Power%20of%20Fine-Tuning&amp;url=https%3a%2f%2flucaspauker.com%2farticles%2fllms-unleashed-the-power-of-fine-tuning%2f">
            <svg version="1.1" xml:space="preserve" viewBox="2 2 28 28" height="30px" width="30px" fill="currentColor">
                <path
                    d="M26.49,29.86H5.5a3.37,3.37,0,0,1-2.47-1,3.35,3.35,0,0,1-1-2.47V5.48A3.36,3.36,0,0,1,3,3,3.37,3.37,0,0,1,5.5,2h21A3.38,3.38,0,0,1,29,3a3.36,3.36,0,0,1,1,2.46V26.37a3.35,3.35,0,0,1-1,2.47A3.38,3.38,0,0,1,26.49,29.86Zm-5.38-6.71a.79.79,0,0,0,.85-.66L24.73,9.24a.55.55,0,0,0-.18-.46.62.62,0,0,0-.41-.17q-.08,0-16.53,6.11a.59.59,0,0,0-.41.59.57.57,0,0,0,.43.52l4,1.24,1.61,4.83a.62.62,0,0,0,.63.43.56.56,0,0,0,.4-.17L16.54,20l4.09,3A.9.9,0,0,0,21.11,23.15ZM13.8,20.71l-1.21-4q8.72-5.55,8.78-5.55c.15,0,.23,0,.23.16a.18.18,0,0,1,0,.06s-2.51,2.3-7.52,6.8Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share LLMs Unleashed: The Power of Fine-Tuning on ycombinator"
            href="https://news.ycombinator.com/submitlink?t=LLMs%20Unleashed%3a%20The%20Power%20of%20Fine-Tuning&u=https%3a%2f%2flucaspauker.com%2farticles%2fllms-unleashed-the-power-of-fine-tuning%2f">
            <svg version="1.1" xml:space="preserve" width="30px" height="30px" viewBox="0 0 512 512" fill="currentColor"
                xmlns:inkscape="http://www.inkscape.org/namespaces/inkscape">
                <path
                    d="M449.446 0C483.971 0 512 28.03 512 62.554L512 449.446C512 483.97 483.97 512 449.446 512L62.554 512C28.03 512 0 483.97 0 449.446L0 62.554C0 28.03 28.029 0 62.554 0L449.446 0ZM183.8767 87.9921H121.8427L230.6673 292.4508V424.0079H281.3328V292.4508L390.1575 87.9921H328.1233L256 238.2489z" />
            </svg>
        </a>
    </li>
</ul>

  </footer>
</article>
    </main>
    
<footer class="footer">
    <span>&copy; 2025 <a href="https://lucaspauker.com/">Lucas Pauker</a></span>
    <span>
        Powered by
        <a href="https://gohugo.io/" rel="noopener noreferrer" target="_blank">Hugo</a> &
        <a href="https://github.com/adityatelange/hugo-PaperMod/" rel="noopener" target="_blank">PaperMod</a>
    </span>
</footer>
<a href="#top" aria-label="go to top" title="Go to Top (Alt + G)" class="top-link" id="top-link" accesskey="g">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentColor">
        <path d="M12 6H0l6-6z" />
    </svg>
</a>

<script>
    let menu = document.getElementById('menu')
    if (menu) {
        menu.scrollLeft = localStorage.getItem("menu-scroll-position");
        menu.onscroll = function () {
            localStorage.setItem("menu-scroll-position", menu.scrollLeft);
        }
    }

    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
        anchor.addEventListener("click", function (e) {
            e.preventDefault();
            var id = this.getAttribute("href").substr(1);
            if (!window.matchMedia('(prefers-reduced-motion: reduce)').matches) {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
                    behavior: "smooth"
                });
            } else {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();
            }
            if (id === "top") {
                history.replaceState(null, null, " ");
            } else {
                history.pushState(null, null, `#${id}`);
            }
        });
    });

</script>
<script>
    var mybutton = document.getElementById("top-link");
    window.onscroll = function () {
        if (document.body.scrollTop > 800 || document.documentElement.scrollTop > 800) {
            mybutton.style.visibility = "visible";
            mybutton.style.opacity = "1";
        } else {
            mybutton.style.visibility = "hidden";
            mybutton.style.opacity = "0";
        }
    };

</script>
<script>
    document.getElementById("theme-toggle").addEventListener("click", () => {
        if (document.body.className.includes("dark")) {
            document.body.classList.remove('dark');
            localStorage.setItem("pref-theme", 'light');
        } else {
            document.body.classList.add('dark');
            localStorage.setItem("pref-theme", 'dark');
        }
    })

</script>
<script>
    document.querySelectorAll('pre > code').forEach((codeblock) => {
        const container = codeblock.parentNode.parentNode;

        const copybutton = document.createElement('button');
        copybutton.classList.add('copy-code');
        copybutton.innerHTML = 'copy';

        function copyingDone() {
            copybutton.innerHTML = 'copied!';
            setTimeout(() => {
                copybutton.innerHTML = 'copy';
            }, 2000);
        }

        copybutton.addEventListener('click', (cb) => {
            if ('clipboard' in navigator) {
                navigator.clipboard.writeText(codeblock.textContent);
                copyingDone();
                return;
            }

            const range = document.createRange();
            range.selectNodeContents(codeblock);
            const selection = window.getSelection();
            selection.removeAllRanges();
            selection.addRange(range);
            try {
                document.execCommand('copy');
                copyingDone();
            } catch (e) { };
            selection.removeRange(range);
        });

        if (container.classList.contains("highlight")) {
            container.appendChild(copybutton);
        } else if (container.parentNode.firstChild == container) {
            
        } else if (codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName == "TABLE") {
            
            codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(copybutton);
        } else {
            
            codeblock.parentNode.appendChild(copybutton);
        }
    });
</script>
</body>

</html>
