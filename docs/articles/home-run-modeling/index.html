<!DOCTYPE html>
<html lang="en" dir="auto">

<head><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="robots" content="index, follow">
<title>Home Run Modeling | Lucas Pauker</title>
<meta name="keywords" content="sports, baseball, cs">
<meta name="description" content="Why home runs? Some of the best moments in baseball games are home runs. Something about hitting the ball out of the park is satisfying. Since baseball season just started, I wanted to model a part of the game. I decided to model home runs since they are pretty rare events but should still be able to be accurately predicted. When I say accurately predicted, I mean that we can accurately predict the probability of a player hitting a home run.">
<meta name="author" content="Lucas Pauker">
<link rel="canonical" href="https://lucaspauker.com/articles/home-run-modeling/">
<link crossorigin="anonymous" href="/assets/css/stylesheet.1b26f33f7c0e27d2dfd006bf15640d83cb41187d24a1b3adfb33ec3a68ceee27.css" integrity="sha256-GybzP3wOJ9Lf0Aa/FWQNg8tBGH0kobOt&#43;zPsOmjO7ic=" rel="preload stylesheet" as="style">
<link rel="icon" href="https://lucaspauker.com/images/logo/favicon.ico">
<link rel="icon" type="image/png" sizes="16x16" href="https://lucaspauker.com/images/logo/favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="https://lucaspauker.com/images/logo/favicon-32x32.png">
<link rel="apple-touch-icon" href="https://lucaspauker.com/images/logo/apple-touch-icon.png">
<link rel="mask-icon" href="https://lucaspauker.com/safari-pinned-tab.svg">
<meta name="theme-color" content="#2e2e33">
<meta name="msapplication-TileColor" content="#2e2e33">
<link rel="alternate" hreflang="en" href="https://lucaspauker.com/articles/home-run-modeling/">
<noscript>
    <style>
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
</noscript>
<script async src="https://www.googletagmanager.com/gtag/js?id=G-49CCEN1B6K"></script>
<script>
var doNotTrack = false;
if (!doNotTrack) {
	window.dataLayer = window.dataLayer || [];
	function gtag(){dataLayer.push(arguments);}
	gtag('js', new Date());
	gtag('config', 'G-49CCEN1B6K', { 'anonymize_ip': false });
}
</script>
<meta property="og:title" content="Home Run Modeling" />
<meta property="og:description" content="Why home runs? Some of the best moments in baseball games are home runs. Something about hitting the ball out of the park is satisfying. Since baseball season just started, I wanted to model a part of the game. I decided to model home runs since they are pretty rare events but should still be able to be accurately predicted. When I say accurately predicted, I mean that we can accurately predict the probability of a player hitting a home run." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://lucaspauker.com/articles/home-run-modeling/" /><meta property="og:image" content="https://lucaspauker.com/images/papermod-cover.png"/><meta property="article:section" content="articles" />
<meta property="article:published_time" content="2024-02-28T00:00:00+00:00" />
<meta property="article:modified_time" content="2024-02-28T00:00:00+00:00" />

<meta name="twitter:card" content="summary_large_image"/>
<meta name="twitter:image" content="https://lucaspauker.com/images/papermod-cover.png"/>

<meta name="twitter:title" content="Home Run Modeling"/>
<meta name="twitter:description" content="Why home runs? Some of the best moments in baseball games are home runs. Something about hitting the ball out of the park is satisfying. Since baseball season just started, I wanted to model a part of the game. I decided to model home runs since they are pretty rare events but should still be able to be accurately predicted. When I say accurately predicted, I mean that we can accurately predict the probability of a player hitting a home run."/>


<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BreadcrumbList",
  "itemListElement": [
    {
      "@type": "ListItem",
      "position":  1 ,
      "name": "Articles",
      "item": "https://lucaspauker.com/articles/"
    }, 
    {
      "@type": "ListItem",
      "position":  2 ,
      "name": "Home Run Modeling",
      "item": "https://lucaspauker.com/articles/home-run-modeling/"
    }
  ]
}
</script>
<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "Home Run Modeling",
  "name": "Home Run Modeling",
  "description": "Why home runs? Some of the best moments in baseball games are home runs. Something about hitting the ball out of the park is satisfying. Since baseball season just started, I wanted to model a part of the game. I decided to model home runs since they are pretty rare events but should still be able to be accurately predicted. When I say accurately predicted, I mean that we can accurately predict the probability of a player hitting a home run.",
  "keywords": [
    "sports", "baseball", "cs"
  ],
  "articleBody": " Why home runs? Some of the best moments in baseball games are home runs. Something about hitting the ball out of the park is satisfying. Since baseball season just started, I wanted to model a part of the game. I decided to model home runs since they are pretty rare events but should still be able to be accurately predicted. When I say accurately predicted, I mean that we can accurately predict the probability of a player hitting a home run. At the end of the day, we can only compare to the true data…but we have many years of baseball data (baseball is nice since there are very detailed statistics and metrics for each player for 100+ years).\nWe are going to model the probability that a player hits a home run in a game. There are only two outcomes: a player hits a home run in the game or they don’t. We will use the past couple years of MLB data to build the model, and if we need more data in the future it is easy to add.\nThere are many challenges that we’ll have to overcome in order to build a good model. First, even though modeling the probability of a player hitting a HR in a game seems relatively simple, there are lots of variables that can affect this probability:\nBatter skill Which pitcher(s) the batter goes against Batter skill against different pitchers How many times a batter bats per game Stadium (different stadiums have different geometry. And location matters: at Coors Field in Denver, balls travel further due to the less dense air.) Weather Probably many other factors I think the most important variables to consider are batter skill, pitcher skill, stadium, and weather. We will start by building a simple model and then add more feature variables to improve the model. We can also iterate on the model itself.\nData data data In order to build a good model, we need good data. Luckily, baseball-reference.com has detailed data from decades of baseball history. For example, we can see that for a given random game, the website lists which players got home runs.\nIn order to think of the data we need, it is helpful to me to think of the interface that we want for our data in order to do the analysis and make it extendable in the future.\nGame class Game: id -\u003e int time -\u003e timestamp location -\u003e str home_team -\u003e str away_team -\u003e str home_team_lineup -\u003e list of Players away_team_lineup -\u003e list of Players Player class Player: _id -\u003e int name -\u003e str pitcher_or_hitter -\u003e bool team_name -\u003e str stats -\u003e dict Batting average -\u003e int On base % -\u003e int ... functions: get_stats_before_game( game_id ) -\u003e dict did_player_hit_homerun( game_id ) -\u003e bool Training data To build the training data, we can do:\nX, y = [], [] for each game in training data: for each player in game: X.append( player.get_stats_before_game( game._id ) ) y.append( player.did_player_hit_homerun( game._id ) ) Then, we can train any binary classification model.\nGraphs After downloading the data for 2022-2023, we will explore it with some graphs and preliminary data analysis. Let’s explore some of the data we have. We will look at data from the 2022 and 2023 regular season. One thing we have to consider is that stats become more consistent as more games are played. For example, if a player has a bad first game they could have a batting average of zero, which will then level out to a more consistent level as more games are played. We can look at the data to see when stats level out. Then, when we train and test our model we can disregard these games. Here are a few stats for Matt Olson, the 2013 batting average leader.\nMatt Olson season stats\nWe can see from this graph that these stats tend to even out after 10-20 games. Let’s also look at batting average for the entire league after a certain number of games:\nLeague batting average over a number of games after first game played\nWe can see that from the top graph it seems that after 20 games, there is a lot less variation in batting average. From the standard deviation in the bottom graph, it also seems that standard deviation levels off after around 20 games. Therefore, we will require at least 20 previous games for a player to train and predict whether they got a home run.\nData analysis We can analyze our 2022/2023 data and see how whether a player hit home runs correlates to our stats. For each game in the 2022 and 2023 regular seasons, we aggregate the stats of each player before the game and whether they hit a home run in that game.\nStat Mean when player did not hit home run Mean when player hit home run Percent difference Batting average 0.246 0.249 +1.27% On base % 0.317 0.322 +1.88% Slugging % 0.401 0.429 +6.87% RBIs per AB 0.125 0.138 +10.21% Home runs per AB 0.033 0.041 +24.60% At Bats Per Game 3.216 3.369.041 +4.74% The stats that change the most are RBIs per AB and home runs per AB. Home runs per AB is the stat that has the most difference between players that hit home runs in a game and those that did not. This makes sense that home runs per AB is a probably a good predictor of if a player will hit a home run in a game.\nWe can see that batting average has only a 1% increase in players that hit a home run in a game compared to players that did not. In contrast, slugging percent increased by 7% between players that hit home runs in a game and those that did not. This makes sense because slugging more directly indicates home run power than batting average. Also players who hit lots of home runs often strike out a lot.\nBuilding the model We will build a binary classification model with logistic regression to predict home run probability per game.\nFeatures We will first build a base model that we can later improve on. For our base model, we only use data from the batter (i.e. batting average, slugging, etc.). Later, we will add data about the starting pitcher and other data. We gather the following stats for each player before each game and use these as our features for the model:\nBatting average Slugging % On base % Home runs per AB RBIs per AB Average ABs per game The last feature, average ABs per game, is important because we are modeling home runs per game not AB. Therefore, a pinch hitter is less likely to hit a home run in a game than a starter since they have less ABs total.\nTrain/test/split We divide our data in train/val/test with proportions of 70% / 10% / 20%. Overall, we have 60k training examples, 8.5k validation examples, and 17k test examples.\nLogistic regression We will use a logistic regression model to do binary classification on whether a player will hit a home run. Logistic regression is good for a base model to do binary classification. To formalize our problem, we assume that we have the \\(i\\text{th}\\) data pair \\(\\left(x_i\\in\\mathbb{R}^m, y_i\\in\\{0,1\\}\\right)\\). \\(x_i\\) is the feature vector and \\(y_i\\) is whether a player hit a home run (1=true and 0=false). For logistic regression, we have our hypothesis function $$h_\\theta(x_i)=\\frac{1}{1-e^{-\\theta^{\\ T}x_i}},$$ This is the logistic function. We are modeling probability \\(p_i\\), $$p_i=P(y_i=1|x_i;\\theta)=h_\\theta(x_i)$$ $$1-p_i=P(y_i=0|x_i;\\theta)=1-h_\\theta(x_i).$$ We see that the likelihood function \\(L\\) is $$L(\\theta)=\\prod_i^{n} \\ p_i^{y_i} \\ \\left(1-p_i\\right)^{1-y_i}.$$\nNow, we maximize the log likelihood function with stochastic gradient descent [1]. We use the sklearn LogisticRegression class to train and test the model.\nEvaluating the model For evaluation, we see that our logistic regression model outputs probabilities, but our ground truth data is only 1 or 0. Therefore, there are two ways we can evaluate our model. The first is to see if the probabilities our model outputs correspond to the estimated true probabilities. The second is to pick a threshold value to convert the probabilities into 1 or 0 and use normal binary classification metrics.\nProbability bins Hitting a home run is inherently random. Even the best player in the best conditions against the best pitcher will not always hit a home run. This is because hitting a home run in baseball is really hard! For evaluation, however, we do not have the true probabilities…we only have whether the player hit a home run in the game or not. Therefore, for evaluation we should simulate a bunch of games with our probabilities and see if it lines up with the real-world results. This process is building probability bins.\nWe have that our logistic regression model \\(f(x_i)=h_{\\theta^*}(x_i)=p_{i, \\text{pred}}\\) outputs a probability of the positive class (home run). We want to look at bins of our logistic model outputs and compare them to the true results.\nFirst, we can divide our \\(N\\) datapoints into groups of 2000 elements. Since our training data had 60k examples, we have 30 total bins.\nFor each bin \\(b\\), there is a set of predicted probs from our model \\(\\alpha=\\{p_{\\text{pred},i\\in b}\\}\\) and a set of true outcomes \\(\\beta=\\{y_{\\text{pred},i\\in b}\\}\\). We then calculate the mean of \\(\\alpha\\) and the mean of \\(\\beta\\) per bin. If our model is accurate, these means should be close.\nProbability bins\nWe can see that the logistic regression does a good job of approximating the true probabilities. It seems at the lower end of the range between 0.05 and 0.10, the model underpredicts pretty consistently. Between 0.10 and 0.15, the model seems to have more variation than at the lower end of the range however.\nIt is also interesting to see how the model predictions are distributed: Predicted probability histogram\nWe can see that our model typically outputs probabilities between 0.05 and 0.16.\nBinary classification metrics Our logistic regression model \\(h_{\\theta^*}(x_i)=p_{i, \\text{pred}}\\) outputs a probability of the positive class (home run). We then predict \\(y_i\\) by $$ y_{i, \\text{pred}} = \\begin{cases} 0, \u0026 \\text{if $p_{i,\\text{pred}}\\geq t$} \\\\ 1, \u0026 \\text{if $p_{i,\\text{pred}}\u003c t$} \\end{cases}\\ , $$ where \\(0\\lt t\\lt 1\\) is the threshold value. We decide to use \\(t\\) as the mean of our predicted probabilities. Here are some binary classification metrics for our model:\nAccuracy 0.575 Precision 0.145 Recall 0.605 F-1 0.234 ROC AUC 0.617 Receiver operating characteristic (ROC) Changing the threshold value affects the true positive rate $$TPR=TP/(TP+FN)=E_i\\left[P(p_{i,\\text{pred}} \\geq t\\ |\\ y_i=1)\\right]$$ and false positive rate $$FPR=FP/(FP+TN)=E_i\\left[P(p_{i,\\text{pred}} \\geq t\\ |\\ y_i=0)\\right],$$ where we have # of true positives \\(TP\\), # false positives \\(FP\\), # true negatives \\(TN\\), and # false negatives \\(FN\\). Graphically, we can look at the distributions of our predicted probabilities for the true positive and negative classes:\nPredicted probability histogram for positive and negative classes\nBy moving the threshold \\(t\\) on the x axis, we can see that the \\(TPR\\) and \\(FPR\\) will be correlated but will change at different rates. If the two distributions were on top of each other, then we would have a random model with no predictive power. On the other hand, if there was no overlap between the distributions, then our model would be able to make predictions perfectly. The receiver operating characteristic (ROC) curve is a graph of the false positive rate compared to the true positive rate.\nROC curve\nRandom guessing produces a straight line on on the ROC graph. The better our model, the higher the area under the curve (ROC) will be.\nFeature importance Stat Model weight Accuracy of model trained without feature Batting average -0.372 0.551 On base % 0.144 0.489 Slugging % 0.287 0.548 Home runs per AB 0.091 0.547 RBIs per AB -0.009 0.551 At bats per game -0.289 0.594 Future improvements It seems that this model performs pretty well overall. However, we are using only batter data right now, so in the future we will add more data about the opposing pitching and other data such as location. We can also try new models to see if it improves our metrics. Lastly, we can train the model on more data and see if it improves. The code used for the data and graphs is here: link.\nCitations https://see.stanford.edu/materials/aimlcs229/cs229-notes1.pdf ",
  "wordCount" : "2040",
  "inLanguage": "en",
  "datePublished": "2024-02-28T00:00:00Z",
  "dateModified": "2024-02-28T00:00:00Z",
  "author":{
    "@type": "Person",
    "name": "Lucas Pauker"
  },
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "https://lucaspauker.com/articles/home-run-modeling/"
  },
  "publisher": {
    "@type": "Organization",
    "name": "Lucas Pauker",
    "logo": {
      "@type": "ImageObject",
      "url": "https://lucaspauker.com/images/logo/favicon.ico"
    }
  }
}
</script><script type="text/javascript" id="MathJax-script" async
  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js">
</script>


</head>

<body class="" id="top">
<script>
    if (localStorage.getItem("pref-theme") === "dark") {
        document.body.classList.add('dark');
    }

</script>

<header class="header">
    <nav class="nav">
        <div class="logo">
            <a href="https://lucaspauker.com/" accesskey="h" title="Lucas Pauker (Alt + H)"></a>
            <div class="logo-switches">
                <button id="theme-toggle" accesskey="t" title="(Alt + T)">
                    <svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path>
                    </svg>
                    <svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <circle cx="12" cy="12" r="5"></circle>
                        <line x1="12" y1="1" x2="12" y2="3"></line>
                        <line x1="12" y1="21" x2="12" y2="23"></line>
                        <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
                        <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
                        <line x1="1" y1="12" x2="3" y2="12"></line>
                        <line x1="21" y1="12" x2="23" y2="12"></line>
                        <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
                        <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
                    </svg>
                </button>
                </ul>
            </div>
        </div>
        <ul id="menu">
            <li>
                <a href="https://lucaspauker.com/" title="Blog">
                    <span>Blog</span>
                </a>
            </li>
            <li>
                <a href="https://lucaspauker.com/about" title="About me">
                    <span>About me</span>
                </a>
            </li>
            <li>
                <a href="https://lucaspauker.com/projects" title="Projects">
                    <span>Projects</span>
                </a>
            </li>
        </ul>
    </nav>
</header>
<main class="main">

<article class="post-single">
  <header class="post-header">
    <div class="breadcrumbs"><a href="https://lucaspauker.com/">Home</a>&nbsp;»&nbsp;<a href="https://lucaspauker.com/articles/">Articles</a></div>
    <h1 class="post-title entry-hint-parent">
      Home Run Modeling
    </h1>
    <div class="post-meta"><span title='2024-02-28 00:00:00 +0000 UTC'>February 28, 2024</span>&nbsp;·&nbsp;10 min&nbsp;·&nbsp;Lucas Pauker

</div>
  </header> <div class="toc">
    <details >
        <summary accesskey="c" title="(Alt + C)">
            <span class="details">Table of Contents</span>
        </summary>

        <div class="inner"><ul>
                <li>
                    <a href="#why-home-runs" aria-label="Why home runs?">Why home runs?</a></li>
                <li>
                    <a href="#data-data-data" aria-label="Data data data">Data data data</a><ul>
                        
                <li>
                    <a href="#game" aria-label="Game">Game</a></li>
                <li>
                    <a href="#player" aria-label="Player">Player</a></li>
                <li>
                    <a href="#training-data" aria-label="Training data">Training data</a></li>
                <li>
                    <a href="#graphs" aria-label="Graphs">Graphs</a></li>
                <li>
                    <a href="#data-analysis" aria-label="Data analysis">Data analysis</a></li></ul>
                </li>
                <li>
                    <a href="#building-the-model" aria-label="Building the model">Building the model</a><ul>
                        
                <li>
                    <a href="#features" aria-label="Features">Features</a></li>
                <li>
                    <a href="#traintestsplit" aria-label="Train/test/split">Train/test/split</a></li>
                <li>
                    <a href="#logistic-regression" aria-label="Logistic regression">Logistic regression</a></li></ul>
                </li>
                <li>
                    <a href="#evaluating-the-model" aria-label="Evaluating the model">Evaluating the model</a><ul>
                        
                <li>
                    <a href="#probability-bins" aria-label="Probability bins">Probability bins</a></li>
                <li>
                    <a href="#binary-classification-metrics" aria-label="Binary classification metrics">Binary classification metrics</a></li>
                <li>
                    <a href="#receiver-operating-characteristic-roc" aria-label="Receiver operating characteristic (ROC)">Receiver operating characteristic (ROC)</a></li></ul>
                </li>
                <li>
                    <a href="#feature-importance" aria-label="Feature importance">Feature importance</a></li>
                <li>
                    <a href="#future-improvements" aria-label="Future improvements">Future improvements</a></li>
                <li>
                    <a href="#citations" aria-label="Citations">Citations</a>
                </li>
            </ul>
        </div>
    </details>
</div>

  <div class="post-content"><p><img loading="lazy" src="/images/baseball_modeling/header_image.png#center" alt="Header image"  />
</p>
<h2 id="why-home-runs">Why home runs?<a hidden class="anchor" aria-hidden="true" href="#why-home-runs">#</a></h2>
<p>Some of the best moments in baseball games are home runs.
Something about hitting the ball out of the park is satisfying.
Since baseball season just started, I wanted to model a part of the game.
I decided to model home runs since they are pretty rare events but should still be able to be accurately predicted.
When I say accurately predicted, I mean that we can accurately predict the probability of a player hitting a home run.
At the end of the day, we can only compare to the true data&hellip;but we have many years of baseball data (baseball is nice since there are very detailed statistics and metrics for each player for 100+ years).</p>
<p>We are going to model the probability that a player hits a home run in a game.
There are only two outcomes: a player hits a home run in the game or they don&rsquo;t.
We will use the past couple years of MLB data to build the model, and if we need more data in the future it is easy to add.</p>
<p>There are many challenges that we&rsquo;ll have to overcome in order to build a good model.
First, even though modeling the probability of a player hitting a HR in a game seems relatively simple, there are lots of variables that can affect this probability:</p>
<ul>
<li>Batter skill</li>
<li>Which pitcher(s) the batter goes against</li>
<li>Batter skill against different pitchers</li>
<li>How many times a batter bats per game</li>
<li>Stadium (different stadiums have different geometry. And location matters: at Coors Field in Denver, balls travel further due to the less dense air.)</li>
<li>Weather</li>
<li>Probably many other factors</li>
</ul>
<p>I think the most important variables to consider are batter skill, pitcher skill, stadium, and weather.
We will start by building a simple model and then add more feature variables to improve the model.
We can also iterate on the model itself.</p>
<h2 id="data-data-data">Data data data<a hidden class="anchor" aria-hidden="true" href="#data-data-data">#</a></h2>
<p>In order to build a good model, we need good data.
Luckily, <a href="https://www.baseball-reference.com/">baseball-reference.com</a> has detailed data from decades of baseball history.
For example, we can see that for a given <a href="https://www.baseball-reference.com/boxes/CHN/CHN202306130.shtml">random game</a>, the website lists which players got home runs.</p>
<p>In order to think of the data we need, it is helpful to me to think of the interface that we want for our data in order to do the analysis and make it extendable in the future.</p>
<h3 id="game">Game<a hidden class="anchor" aria-hidden="true" href="#game">#</a></h3>
<pre tabindex="0"><code>class Game:
    id -&gt; int
    time -&gt; timestamp
    location -&gt; str
    home_team -&gt; str
    away_team -&gt; str
    home_team_lineup -&gt; list of Players
    away_team_lineup -&gt; list of Players
</code></pre><h3 id="player">Player<a hidden class="anchor" aria-hidden="true" href="#player">#</a></h3>
<pre tabindex="0"><code>class Player:
    _id -&gt; int
    name -&gt; str
    pitcher_or_hitter -&gt; bool
    team_name -&gt; str
    stats -&gt; dict
        Batting average -&gt; int
        On base % -&gt; int
        ...

    functions:
        get_stats_before_game( game_id ) -&gt; dict
        did_player_hit_homerun( game_id ) -&gt; bool
</code></pre><h3 id="training-data">Training data<a hidden class="anchor" aria-hidden="true" href="#training-data">#</a></h3>
<p>To build the training data, we can do:</p>
<pre tabindex="0"><code>X, y = [], []
for each game in training data:
    for each player in game:
        X.append( player.get_stats_before_game( game._id ) )
        y.append( player.did_player_hit_homerun( game._id ) )
</code></pre><p>Then, we can train any binary classification model.</p>
<h3 id="graphs">Graphs<a hidden class="anchor" aria-hidden="true" href="#graphs">#</a></h3>
<p>After downloading the data for 2022-2023, we will explore it with some graphs and preliminary data analysis.
Let&rsquo;s explore some of the data we have.
We will look at data from the 2022 and 2023 regular season.
One thing we have to consider is that stats become more consistent as more games are played.
For example, if a player has a bad first game they could have a batting average of zero, which will then level out to a more consistent level as more games are played.
We can look at the data to see when stats level out.
Then, when we train and test our model we can disregard these games.
Here are a few stats for Matt Olson, the 2013 <a href="https://www.espn.com/mlb/history/season/_/year/2013">batting average leader</a>.</p>
<p><img loading="lazy" src="/images/baseball_modeling/matt_olson_stats.png#center" alt="Matt Olson stats"  />

<em>Matt Olson season stats</em></p>
<p>We can see from this graph that these stats tend to even out after 10-20 games.
Let&rsquo;s also look at batting average for the entire league after a certain number of games:</p>
<p><img loading="lazy" src="/images/baseball_modeling/all_players_batting_average.png#center" alt="League batting average"  />

<em>League batting average over a number of games after first game played</em></p>
<p>We can see that from the top graph it seems that after 20 games, there is a lot less variation in batting average.
From the standard deviation in the bottom graph, it also seems that standard deviation levels off after around 20 games.
Therefore, we will require at least 20 previous games for a player to train and predict whether they got a home run.</p>
<h3 id="data-analysis">Data analysis<a hidden class="anchor" aria-hidden="true" href="#data-analysis">#</a></h3>
<p>We can analyze our 2022/2023 data and see how whether a player hit home runs correlates to our stats.
For each game in the 2022 and 2023 regular seasons, we aggregate the stats of each player <em>before</em> the game and whether they hit a home run in that game.</p>
<table>
<thead>
<tr>
<th>Stat</th>
<th style="text-align:center">Mean when player did not hit home run</th>
<th style="text-align:center">Mean when player hit home run</th>
<th style="text-align:center">Percent difference</th>
</tr>
</thead>
<tbody>
<tr>
<td>Batting average</td>
<td style="text-align:center">0.246</td>
<td style="text-align:center">0.249</td>
<td style="text-align:center">+1.27%</td>
</tr>
<tr>
<td>On base %</td>
<td style="text-align:center">0.317</td>
<td style="text-align:center">0.322</td>
<td style="text-align:center">+1.88%</td>
</tr>
<tr>
<td>Slugging %</td>
<td style="text-align:center">0.401</td>
<td style="text-align:center">0.429</td>
<td style="text-align:center">+6.87%</td>
</tr>
<tr>
<td>RBIs per AB</td>
<td style="text-align:center">0.125</td>
<td style="text-align:center">0.138</td>
<td style="text-align:center">+10.21%</td>
</tr>
<tr>
<td>Home runs per AB</td>
<td style="text-align:center">0.033</td>
<td style="text-align:center">0.041</td>
<td style="text-align:center">+24.60%</td>
</tr>
<tr>
<td>At Bats Per Game</td>
<td style="text-align:center">3.216</td>
<td style="text-align:center">3.369.041</td>
<td style="text-align:center">+4.74%</td>
</tr>
</tbody>
</table>
<p>The stats that change the most are RBIs per AB and home runs per AB.
Home runs per AB is the stat that has the most difference between players that hit home runs in a game and those that did not.
This makes sense that home runs per AB is a probably a good predictor of if a player will hit a home run in a game.</p>
<p>We can see that batting average has only a 1% increase in players that hit a home run in a game compared to players that did not.
In contrast, slugging percent increased by 7% between players that hit home runs in a game and those that did not.
This makes sense because slugging more directly indicates home run power than batting average.
Also players who hit lots of home runs often strike out a lot.</p>
<h2 id="building-the-model">Building the model<a hidden class="anchor" aria-hidden="true" href="#building-the-model">#</a></h2>
<p>We will build a binary classification model with logistic regression to predict home run probability per game.</p>
<h3 id="features">Features<a hidden class="anchor" aria-hidden="true" href="#features">#</a></h3>
<p>We will first build a base model that we can later improve on.
For our base model, we only use data from the batter (i.e. batting average, slugging, etc.).
Later, we will add data about the starting pitcher and other data.
We gather the following stats for each player before each game and use these as our features for the model:</p>
<ul>
<li>Batting average</li>
<li>Slugging %</li>
<li>On base %</li>
<li>Home runs per AB</li>
<li>RBIs per AB</li>
<li>Average ABs per game</li>
</ul>
<p>The last feature, average ABs per game, is important because we are modeling home runs per <em>game</em> not <em>AB</em>.
Therefore, a pinch hitter is less likely to hit a home run in a game than a starter since they have less ABs total.</p>
<h3 id="traintestsplit">Train/test/split<a hidden class="anchor" aria-hidden="true" href="#traintestsplit">#</a></h3>
<p>We divide our data in train/val/test with proportions of 70% / 10% / 20%.
Overall, we have 60k training examples, 8.5k validation examples, and 17k test examples.</p>
<h3 id="logistic-regression">Logistic regression<a hidden class="anchor" aria-hidden="true" href="#logistic-regression">#</a></h3>
<p>We will use a logistic regression model to do binary classification on whether a player will hit a home run.
Logistic regression is good for a base model to do binary classification.
To formalize our problem, we assume that we have the \(i\text{th}\) data pair \(\left(x_i\in\mathbb{R}^m, y_i\in\{0,1\}\right)\).
\(x_i\) is the feature vector and \(y_i\) is whether a player hit a home run (1=true and 0=false).
For logistic regression, we have our hypothesis function
$$h_\theta(x_i)=\frac{1}{1-e^{-\theta^{\ T}x_i}},$$
This is the logistic function.
We are modeling probability \(p_i\),
$$p_i=P(y_i=1|x_i;\theta)=h_\theta(x_i)$$
$$1-p_i=P(y_i=0|x_i;\theta)=1-h_\theta(x_i).$$
We see that the likelihood function \(L\) is
$$L(\theta)=\prod_i^{n} \ p_i^{y_i} \ \left(1-p_i\right)^{1-y_i}.$$</p>
<p>Now, we maximize the log likelihood function with stochastic gradient descent [1].
We use the sklearn <code>LogisticRegression</code> class to train and test the model.</p>
<h2 id="evaluating-the-model">Evaluating the model<a hidden class="anchor" aria-hidden="true" href="#evaluating-the-model">#</a></h2>
<p>For evaluation, we see that our logistic regression model outputs probabilities, but our ground truth data is only 1 or 0.
Therefore, there are two ways we can evaluate our model.
The first is to see if the probabilities our model outputs correspond to the estimated true probabilities.
The second is to pick a threshold value to convert the probabilities into 1 or 0 and use normal binary classification metrics.</p>
<h3 id="probability-bins">Probability bins<a hidden class="anchor" aria-hidden="true" href="#probability-bins">#</a></h3>
<p>Hitting a home run is inherently random.
Even the best player in the best conditions against the best pitcher will not always hit a home run.
This is because hitting a home run in baseball is really hard!
For evaluation, however, we do not have the true probabilities&hellip;we only have whether the player hit a home run in the game or not.
Therefore, for evaluation we should simulate a bunch of games with our probabilities and see if it lines up with the real-world results.
This process is building probability bins.</p>
<p>We have that our logistic regression model \(f(x_i)=h_{\theta^*}(x_i)=p_{i, \text{pred}}\) outputs a probability of the positive class (home run).
We want to look at bins of our logistic model outputs and compare them to the true results.</p>
<p>First, we can divide our \(N\) datapoints into groups of 2000 elements.
Since our training data had 60k examples, we have 30 total bins.</p>
<p>For each bin \(b\), there is a set of predicted probs from our model \(\alpha=\{p_{\text{pred},i\in b}\}\) and a set of true outcomes \(\beta=\{y_{\text{pred},i\in b}\}\).
We then calculate the mean of \(\alpha\) and the mean of \(\beta\) per bin.
If our model is accurate, these means should be close.</p>
<p><img loading="lazy" src="/images/baseball_modeling/probability_buckets.png#center" alt="Probability bins"  />

<em>Probability bins</em></p>
<p>We can see that the logistic regression does a good job of approximating the true probabilities.
It seems at the lower end of the range between 0.05 and 0.10, the model underpredicts pretty consistently.
Between 0.10 and 0.15, the model seems to have more variation than at the lower end of the range however.</p>
<p>It is also interesting to see how the model predictions are distributed:
<img loading="lazy" src="/images/baseball_modeling/predicted_probability_distribution.png#center" alt="Predicted probability histogram"  />

<em>Predicted probability histogram</em></p>
<p>We can see that our model typically outputs probabilities between 0.05 and 0.16.</p>
<h3 id="binary-classification-metrics">Binary classification metrics<a hidden class="anchor" aria-hidden="true" href="#binary-classification-metrics">#</a></h3>
<p>Our logistic regression model \(h_{\theta^*}(x_i)=p_{i, \text{pred}}\) outputs a probability of the positive class (home run).
We then predict \(y_i\) by
$$
y_{i, \text{pred}} =
\begin{cases}
0,  &amp; \text{if $p_{i,\text{pred}}\geq t$} \\
1, &amp; \text{if $p_{i,\text{pred}}&lt; t$}
\end{cases}\ ,
$$
where \(0\lt t\lt 1\) is the threshold value.
We decide to use \(t\) as the mean of our predicted probabilities.
Here are some binary classification metrics for our model:</p>
<table>
<thead>
<tr>
<th></th>
<th></th>
</tr>
</thead>
<tbody>
<tr>
<td>Accuracy</td>
<td>0.575</td>
</tr>
<tr>
<td>Precision</td>
<td>0.145</td>
</tr>
<tr>
<td>Recall</td>
<td>0.605</td>
</tr>
<tr>
<td>F-1</td>
<td>0.234</td>
</tr>
<tr>
<td>ROC AUC</td>
<td>0.617</td>
</tr>
</tbody>
</table>
<h3 id="receiver-operating-characteristic-roc">Receiver operating characteristic (ROC)<a hidden class="anchor" aria-hidden="true" href="#receiver-operating-characteristic-roc">#</a></h3>
<p>Changing the threshold value affects the true positive rate
$$TPR=TP/(TP+FN)=E_i\left[P(p_{i,\text{pred}} \geq t\ |\ y_i=1)\right]$$
and false positive rate
$$FPR=FP/(FP+TN)=E_i\left[P(p_{i,\text{pred}} \geq t\ |\ y_i=0)\right],$$
where we have # of true positives \(TP\), # false positives \(FP\), # true negatives \(TN\), and # false negatives \(FN\).
Graphically, we can look at the distributions of our predicted probabilities for the true positive and negative classes:</p>
<p><img loading="lazy" src="/images/baseball_modeling/predicted_probability_distribution_pos_neg.png#center" alt="Predicted probability histogram for positive and negative classes"  />

<em>Predicted probability histogram for positive and negative classes</em></p>
<p>By moving the threshold \(t\) on the x axis, we can see that the \(TPR\) and \(FPR\) will be correlated but will change at different rates.
If the two distributions were on top of each other, then we would have a random model with no predictive power.
On the other hand, if there was no overlap between the distributions, then our model would be able to make predictions perfectly.
The receiver operating characteristic (ROC) curve is a graph of the false positive rate compared to the true positive rate.</p>
<p><img loading="lazy" src="/images/baseball_modeling/roc_curve.png#center" alt="ROC curve"  />

<em>ROC curve</em></p>
<p>Random guessing produces a straight line on on the ROC graph.
The better our model, the higher the area under the curve (ROC) will be.</p>
<h2 id="feature-importance">Feature importance<a hidden class="anchor" aria-hidden="true" href="#feature-importance">#</a></h2>
<table>
<thead>
<tr>
<th>Stat</th>
<th style="text-align:center">Model weight</th>
<th style="text-align:center">Accuracy of model trained <br>without feature</th>
</tr>
</thead>
<tbody>
<tr>
<td>Batting average</td>
<td style="text-align:center"><strong>-0.372</strong></td>
<td style="text-align:center">0.551</td>
</tr>
<tr>
<td>On base %</td>
<td style="text-align:center">0.144</td>
<td style="text-align:center"><strong>0.489</strong></td>
</tr>
<tr>
<td>Slugging %</td>
<td style="text-align:center">0.287</td>
<td style="text-align:center">0.548</td>
</tr>
<tr>
<td>Home runs per AB</td>
<td style="text-align:center">0.091</td>
<td style="text-align:center">0.547</td>
</tr>
<tr>
<td>RBIs per AB</td>
<td style="text-align:center">-0.009</td>
<td style="text-align:center">0.551</td>
</tr>
<tr>
<td>At bats per game</td>
<td style="text-align:center">-0.289</td>
<td style="text-align:center">0.594</td>
</tr>
</tbody>
</table>
<h2 id="future-improvements">Future improvements<a hidden class="anchor" aria-hidden="true" href="#future-improvements">#</a></h2>
<p>It seems that this model performs pretty well overall.
However, we are using only batter data right now, so in the future we will add more data about the opposing pitching and other data such as location.
We can also try new models to see if it improves our metrics.
Lastly, we can train the model on more data and see if it improves.
The code used for the data and graphs is here: <a href="https://github.com/lucaspauker/home_run_modeling">link</a>.</p>
<h2 id="citations">Citations<a hidden class="anchor" aria-hidden="true" href="#citations">#</a></h2>
<ol>
<li><a href="https://see.stanford.edu/materials/aimlcs229/cs229-notes1.pdf">https://see.stanford.edu/materials/aimlcs229/cs229-notes1.pdf</a></li>
</ol>


  </div>

  <footer class="post-footer">
    <ul class="post-tags">
      <li><a href="https://lucaspauker.com/tags/sports/">Sports</a></li>
      <li><a href="https://lucaspauker.com/tags/baseball/">Baseball</a></li>
      <li><a href="https://lucaspauker.com/tags/cs/">CS</a></li>
    </ul>
    <script src="https://utteranc.es/client.js"
        repo="lucaspauker/lucaspauker.com"
        issue-term="url"
        theme="github-light"
        crossorigin="anonymous"
        async>
    </script>
<nav class="paginav">
  <a class="prev" href="https://lucaspauker.com/articles/charity-calculator/">
    <span class="title">« Prev</span>
    <br>
    <span>Charity Calculator</span>
  </a>
  <a class="next" href="https://lucaspauker.com/articles/openai-model-timing/">
    <span class="title">Next »</span>
    <br>
    <span>OpenAI Model Timing</span>
  </a>
</nav>


<ul class="share-buttons">
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share Home Run Modeling on x"
            href="https://x.com/intent/tweet/?text=Home%20Run%20Modeling&amp;url=https%3a%2f%2flucaspauker.com%2farticles%2fhome-run-modeling%2f&amp;hashtags=sports%2cbaseball%2ccs">
            <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
                <path
                    d="M512 62.554 L 512 449.446 C 512 483.97 483.97 512 449.446 512 L 62.554 512 C 28.03 512 0 483.97 0 449.446 L 0 62.554 C 0 28.03 28.029 0 62.554 0 L 449.446 0 C 483.971 0 512 28.03 512 62.554 Z M 269.951 190.75 L 182.567 75.216 L 56 75.216 L 207.216 272.95 L 63.9 436.783 L 125.266 436.783 L 235.9 310.383 L 332.567 436.783 L 456 436.783 L 298.367 228.367 L 432.367 75.216 L 371.033 75.216 Z M 127.633 110 L 164.101 110 L 383.481 400.065 L 349.5 400.065 Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share Home Run Modeling on linkedin"
            href="https://www.linkedin.com/shareArticle?mini=true&amp;url=https%3a%2f%2flucaspauker.com%2farticles%2fhome-run-modeling%2f&amp;title=Home%20Run%20Modeling&amp;summary=Home%20Run%20Modeling&amp;source=https%3a%2f%2flucaspauker.com%2farticles%2fhome-run-modeling%2f">
            <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
                <path
                    d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-386.892,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Zm-288.985,423.278l0,-225.717l-75.04,0l0,225.717l75.04,0Zm270.539,0l0,-129.439c0,-69.333 -37.018,-101.586 -86.381,-101.586c-39.804,0 -57.634,21.891 -67.617,37.266l0,-31.958l-75.021,0c0.995,21.181 0,225.717 0,225.717l75.02,0l0,-126.056c0,-6.748 0.486,-13.492 2.474,-18.315c5.414,-13.475 17.767,-27.434 38.494,-27.434c27.135,0 38.007,20.707 38.007,51.037l0,120.768l75.024,0Zm-307.552,-334.556c-25.674,0 -42.448,16.879 -42.448,39.002c0,21.658 16.264,39.002 41.455,39.002l0.484,0c26.165,0 42.452,-17.344 42.452,-39.002c-0.485,-22.092 -16.241,-38.954 -41.943,-39.002Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share Home Run Modeling on reddit"
            href="https://reddit.com/submit?url=https%3a%2f%2flucaspauker.com%2farticles%2fhome-run-modeling%2f&title=Home%20Run%20Modeling">
            <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
                <path
                    d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-386.892,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Zm-3.446,265.638c0,-22.964 -18.616,-41.58 -41.58,-41.58c-11.211,0 -21.361,4.457 -28.841,11.666c-28.424,-20.508 -67.586,-33.757 -111.204,-35.278l18.941,-89.121l61.884,13.157c0.756,15.734 13.642,28.29 29.56,28.29c16.407,0 29.706,-13.299 29.706,-29.701c0,-16.403 -13.299,-29.702 -29.706,-29.702c-11.666,0 -21.657,6.792 -26.515,16.578l-69.105,-14.69c-1.922,-0.418 -3.939,-0.042 -5.585,1.036c-1.658,1.073 -2.811,2.761 -3.224,4.686l-21.152,99.438c-44.258,1.228 -84.046,14.494 -112.837,35.232c-7.468,-7.164 -17.589,-11.591 -28.757,-11.591c-22.965,0 -41.585,18.616 -41.585,41.58c0,16.896 10.095,31.41 24.568,37.918c-0.639,4.135 -0.99,8.328 -0.99,12.576c0,63.977 74.469,115.836 166.33,115.836c91.861,0 166.334,-51.859 166.334,-115.836c0,-4.218 -0.347,-8.387 -0.977,-12.493c14.564,-6.47 24.735,-21.034 24.735,-38.001Zm-119.474,108.193c-20.27,20.241 -59.115,21.816 -70.534,21.816c-11.428,0 -50.277,-1.575 -70.522,-21.82c-3.007,-3.008 -3.007,-7.882 0,-10.889c3.003,-2.999 7.882,-3.003 10.885,0c12.777,12.781 40.11,17.317 59.637,17.317c19.522,0 46.86,-4.536 59.657,-17.321c3.016,-2.999 7.886,-2.995 10.885,0.008c3.008,3.011 3.003,7.882 -0.008,10.889Zm-5.23,-48.781c-16.373,0 -29.701,-13.324 -29.701,-29.698c0,-16.381 13.328,-29.714 29.701,-29.714c16.378,0 29.706,13.333 29.706,29.714c0,16.374 -13.328,29.698 -29.706,29.698Zm-160.386,-29.702c0,-16.381 13.328,-29.71 29.714,-29.71c16.369,0 29.689,13.329 29.689,29.71c0,16.373 -13.32,29.693 -29.689,29.693c-16.386,0 -29.714,-13.32 -29.714,-29.693Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share Home Run Modeling on facebook"
            href="https://facebook.com/sharer/sharer.php?u=https%3a%2f%2flucaspauker.com%2farticles%2fhome-run-modeling%2f">
            <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
                <path
                    d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-106.468,0l0,-192.915l66.6,0l12.672,-82.621l-79.272,0l0,-53.617c0,-22.603 11.073,-44.636 46.58,-44.636l36.042,0l0,-70.34c0,0 -32.71,-5.582 -63.982,-5.582c-65.288,0 -107.96,39.569 -107.96,111.204l0,62.971l-72.573,0l0,82.621l72.573,0l0,192.915l-191.104,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share Home Run Modeling on whatsapp"
            href="https://api.whatsapp.com/send?text=Home%20Run%20Modeling%20-%20https%3a%2f%2flucaspauker.com%2farticles%2fhome-run-modeling%2f">
            <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
                <path
                    d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-386.892,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Zm-58.673,127.703c-33.842,-33.881 -78.847,-52.548 -126.798,-52.568c-98.799,0 -179.21,80.405 -179.249,179.234c-0.013,31.593 8.241,62.428 23.927,89.612l-25.429,92.884l95.021,-24.925c26.181,14.28 55.659,21.807 85.658,21.816l0.074,0c98.789,0 179.206,-80.413 179.247,-179.243c0.018,-47.895 -18.61,-92.93 -52.451,-126.81Zm-126.797,275.782l-0.06,0c-26.734,-0.01 -52.954,-7.193 -75.828,-20.767l-5.441,-3.229l-56.386,14.792l15.05,-54.977l-3.542,-5.637c-14.913,-23.72 -22.791,-51.136 -22.779,-79.287c0.033,-82.142 66.867,-148.971 149.046,-148.971c39.793,0.014 77.199,15.531 105.329,43.692c28.128,28.16 43.609,65.592 43.594,105.4c-0.034,82.149 -66.866,148.983 -148.983,148.984Zm81.721,-111.581c-4.479,-2.242 -26.499,-13.075 -30.604,-14.571c-4.105,-1.495 -7.091,-2.241 -10.077,2.241c-2.986,4.483 -11.569,14.572 -14.182,17.562c-2.612,2.988 -5.225,3.364 -9.703,1.12c-4.479,-2.241 -18.91,-6.97 -36.017,-22.23c-13.314,-11.876 -22.304,-26.542 -24.916,-31.026c-2.612,-4.484 -0.279,-6.908 1.963,-9.14c2.016,-2.007 4.48,-5.232 6.719,-7.847c2.24,-2.615 2.986,-4.484 4.479,-7.472c1.493,-2.99 0.747,-5.604 -0.374,-7.846c-1.119,-2.241 -10.077,-24.288 -13.809,-33.256c-3.635,-8.733 -7.327,-7.55 -10.077,-7.688c-2.609,-0.13 -5.598,-0.158 -8.583,-0.158c-2.986,0 -7.839,1.121 -11.944,5.604c-4.105,4.484 -15.675,15.32 -15.675,37.364c0,22.046 16.048,43.342 18.287,46.332c2.24,2.99 31.582,48.227 76.511,67.627c10.685,4.615 19.028,7.371 25.533,9.434c10.728,3.41 20.492,2.929 28.209,1.775c8.605,-1.285 26.499,-10.833 30.231,-21.295c3.732,-10.464 3.732,-19.431 2.612,-21.298c-1.119,-1.869 -4.105,-2.99 -8.583,-5.232Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share Home Run Modeling on telegram"
            href="https://telegram.me/share/url?text=Home%20Run%20Modeling&amp;url=https%3a%2f%2flucaspauker.com%2farticles%2fhome-run-modeling%2f">
            <svg version="1.1" xml:space="preserve" viewBox="2 2 28 28" height="30px" width="30px" fill="currentColor">
                <path
                    d="M26.49,29.86H5.5a3.37,3.37,0,0,1-2.47-1,3.35,3.35,0,0,1-1-2.47V5.48A3.36,3.36,0,0,1,3,3,3.37,3.37,0,0,1,5.5,2h21A3.38,3.38,0,0,1,29,3a3.36,3.36,0,0,1,1,2.46V26.37a3.35,3.35,0,0,1-1,2.47A3.38,3.38,0,0,1,26.49,29.86Zm-5.38-6.71a.79.79,0,0,0,.85-.66L24.73,9.24a.55.55,0,0,0-.18-.46.62.62,0,0,0-.41-.17q-.08,0-16.53,6.11a.59.59,0,0,0-.41.59.57.57,0,0,0,.43.52l4,1.24,1.61,4.83a.62.62,0,0,0,.63.43.56.56,0,0,0,.4-.17L16.54,20l4.09,3A.9.9,0,0,0,21.11,23.15ZM13.8,20.71l-1.21-4q8.72-5.55,8.78-5.55c.15,0,.23,0,.23.16a.18.18,0,0,1,0,.06s-2.51,2.3-7.52,6.8Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share Home Run Modeling on ycombinator"
            href="https://news.ycombinator.com/submitlink?t=Home%20Run%20Modeling&u=https%3a%2f%2flucaspauker.com%2farticles%2fhome-run-modeling%2f">
            <svg version="1.1" xml:space="preserve" width="30px" height="30px" viewBox="0 0 512 512" fill="currentColor"
                xmlns:inkscape="http://www.inkscape.org/namespaces/inkscape">
                <path
                    d="M449.446 0C483.971 0 512 28.03 512 62.554L512 449.446C512 483.97 483.97 512 449.446 512L62.554 512C28.03 512 0 483.97 0 449.446L0 62.554C0 28.03 28.029 0 62.554 0L449.446 0ZM183.8767 87.9921H121.8427L230.6673 292.4508V424.0079H281.3328V292.4508L390.1575 87.9921H328.1233L256 238.2489z" />
            </svg>
        </a>
    </li>
</ul>

  </footer>
</article>
    </main>
    
<footer class="footer">
    <span>&copy; 2025 <a href="https://lucaspauker.com/">Lucas Pauker</a></span>
    <span>
        Powered by
        <a href="https://gohugo.io/" rel="noopener noreferrer" target="_blank">Hugo</a> &
        <a href="https://github.com/adityatelange/hugo-PaperMod/" rel="noopener" target="_blank">PaperMod</a>
    </span>
</footer>
<a href="#top" aria-label="go to top" title="Go to Top (Alt + G)" class="top-link" id="top-link" accesskey="g">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentColor">
        <path d="M12 6H0l6-6z" />
    </svg>
</a>

<script>
    let menu = document.getElementById('menu')
    if (menu) {
        menu.scrollLeft = localStorage.getItem("menu-scroll-position");
        menu.onscroll = function () {
            localStorage.setItem("menu-scroll-position", menu.scrollLeft);
        }
    }

    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
        anchor.addEventListener("click", function (e) {
            e.preventDefault();
            var id = this.getAttribute("href").substr(1);
            if (!window.matchMedia('(prefers-reduced-motion: reduce)').matches) {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
                    behavior: "smooth"
                });
            } else {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();
            }
            if (id === "top") {
                history.replaceState(null, null, " ");
            } else {
                history.pushState(null, null, `#${id}`);
            }
        });
    });

</script>
<script>
    var mybutton = document.getElementById("top-link");
    window.onscroll = function () {
        if (document.body.scrollTop > 800 || document.documentElement.scrollTop > 800) {
            mybutton.style.visibility = "visible";
            mybutton.style.opacity = "1";
        } else {
            mybutton.style.visibility = "hidden";
            mybutton.style.opacity = "0";
        }
    };

</script>
<script>
    document.getElementById("theme-toggle").addEventListener("click", () => {
        if (document.body.className.includes("dark")) {
            document.body.classList.remove('dark');
            localStorage.setItem("pref-theme", 'light');
        } else {
            document.body.classList.add('dark');
            localStorage.setItem("pref-theme", 'dark');
        }
    })

</script>
<script>
    document.querySelectorAll('pre > code').forEach((codeblock) => {
        const container = codeblock.parentNode.parentNode;

        const copybutton = document.createElement('button');
        copybutton.classList.add('copy-code');
        copybutton.innerHTML = 'copy';

        function copyingDone() {
            copybutton.innerHTML = 'copied!';
            setTimeout(() => {
                copybutton.innerHTML = 'copy';
            }, 2000);
        }

        copybutton.addEventListener('click', (cb) => {
            if ('clipboard' in navigator) {
                navigator.clipboard.writeText(codeblock.textContent);
                copyingDone();
                return;
            }

            const range = document.createRange();
            range.selectNodeContents(codeblock);
            const selection = window.getSelection();
            selection.removeAllRanges();
            selection.addRange(range);
            try {
                document.execCommand('copy');
                copyingDone();
            } catch (e) { };
            selection.removeRange(range);
        });

        if (container.classList.contains("highlight")) {
            container.appendChild(copybutton);
        } else if (container.parentNode.firstChild == container) {
            
        } else if (codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName == "TABLE") {
            
            codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(copybutton);
        } else {
            
            codeblock.parentNode.appendChild(copybutton);
        }
    });
</script>
</body>

</html>
